{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from featexp import get_trend_stats\n",
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from numpy import sort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_train (260601, 38)\n",
      "df_x_test (86868, 38)\n",
      "data_train (260601, 39)\n",
      "len train: 260601\n",
      "len train: 86868\n"
     ]
    }
   ],
   "source": [
    "dir_data = \"/Users/romulo/Documents/Dataset/Earthquake Damage/\"\n",
    "#dir_data = \"Dataset/\"\n",
    "df_x_train = pd.read_csv(dir_data+\"train_values.csv\",index_col=\"building_id\")\n",
    "print(\"df_x_train\",df_x_train.shape)\n",
    "df_y_train = pd.read_csv(dir_data+\"train_labels.csv\",index_col=\"building_id\")\n",
    "df_x_test = pd.read_csv(dir_data+\"test_values.csv\",index_col=\"building_id\")\n",
    "print(\"df_x_test\",df_x_test.shape)\n",
    "\n",
    "#df_x_train = df_x_train[:100]\n",
    "#df_y_train = df_y_train[:100]\n",
    "#df_x_test = df_x_test[:100]\n",
    "\n",
    "data_train = df_x_train.merge(df_y_train, how='left', left_index=True, right_index=True)\n",
    "print(\"data_train\",data_train.shape)\n",
    "\n",
    "\n",
    "print(\"len train:\",len(data_train))\n",
    "print(\"len train:\",len(df_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y train\n",
    "y_train = data_train['damage_grade'].values\n",
    "\n",
    "# remove y of data_train\n",
    "data_train = data_train.drop('damage_grade', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_x_all: (347469, 38)\n",
      "x_train: (260601, 68)\n",
      "x_test: (86868, 68)\n"
     ]
    }
   ],
   "source": [
    "# let's put the train data and test data together to make get_dummies and then divide\n",
    "df_x_all = data_train.append(df_x_test)\n",
    "print(\"df_x_all:\",df_x_all.shape)\n",
    "\n",
    "# get dummies from cat columns\n",
    "cat_var = [key for key in dict(df_x_all.dtypes) if dict(df_x_all.dtypes)[key] in ['object'] ]\n",
    "df_x_all = pd.get_dummies(df_x_all, prefix=cat_var, columns=cat_var)\n",
    "\n",
    "#divide x_train and x_test\n",
    "x_train = df_x_all.iloc[:len(data_train)]\n",
    "x_test = df_x_all.iloc[len(data_train):]\n",
    "\n",
    "print(\"x_train:\",x_train.shape)\n",
    "print(\"x_test:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260601, 68)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86868, 68)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del df_x_all,df_x_train,df_y_train,data_train,df_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get x_dev and y_dev (10% from train)\n",
    "#x_train, x_dev, y_train, y_dev = train_test_split( x_train, y_train, test_size=0.1, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x_train : 260601  len y_train: 260601 \n",
      "len x_test  : 86868\n"
     ]
    }
   ],
   "source": [
    "print(\"len x_train : %d  len y_train: %d \" %(len(x_train),len(y_train)) )\n",
    "#print(\"len x_dev   : %d  len y_dev  : %d \" %(len(x_dev),len(y_dev)) )\n",
    "print(\"len x_test  : %d\" %(len(x_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\taccuracy_train 0.8981162773742234\n"
     ]
    }
   ],
   "source": [
    "max_depth = 9\n",
    "n_estimator =  2000\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=n_estimator,max_depth=max_depth)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "#Eval\n",
    "y_train_pred = model.predict(x_train)\n",
    "\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "print(\"\\taccuracy_train\",accuracy_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIME TO PREDICT AND SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv(dir_data + 'submission_format.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=predictions,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('XGBClassifier_2000_all_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
