{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train: 260601\n",
      "len train: 86868\n"
     ]
    }
   ],
   "source": [
    "dir_data = \"/Users/romulo/Documents/Dataset/Earthquake Damage/\"\n",
    "#dir_data = \"Dataset/\"\n",
    "df_x_train = pd.read_csv(dir_data+\"train_values.csv\",index_col=\"building_id\")\n",
    "df_y_train = pd.read_csv(dir_data+\"train_labels.csv\",index_col=\"building_id\")\n",
    "df_x_test = pd.read_csv(dir_data+\"test_values.csv\",index_col=\"building_id\")\n",
    "\n",
    "#df_x_train = df_x_train[:100]\n",
    "#df_y_train = df_y_train[:100]\n",
    "#df_x_test = df_x_test[:100]\n",
    "\n",
    "data_train = df_x_train.merge(df_y_train, how='left', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "print(\"len train:\",len(data_train))\n",
    "print(\"len train:\",len(df_x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get y train\n",
    "y_train = data_train['damage_grade'].values\n",
    "\n",
    "# remove y of data_train\n",
    "data_train = data_train.drop('damage_grade', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len all: 347469\n"
     ]
    }
   ],
   "source": [
    "# let's put the train data and test data together to make get_dummies and then divide\n",
    "df_x_all = data_train.append(df_x_test)\n",
    "print(\"len all:\",len(df_x_all))\n",
    "\n",
    "# get dummies from cat columns\n",
    "cat_var = [key for key in dict(df_x_all.dtypes) if dict(df_x_all.dtypes)[key] in ['object'] ]\n",
    "df_x_all = pd.get_dummies(df_x_all, prefix=cat_var, columns=cat_var)\n",
    "\n",
    "#divide x_train and x_test\n",
    "x_train = df_x_all.iloc[:len(data_train)]\n",
    "x_test = df_x_all.iloc[len(data_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del df_x_all,df_x_train,df_y_train,data_train,df_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get x_dev and y_dev (10% from train)\n",
    "x_train, x_dev, y_train, y_dev = train_test_split( x_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x_train : 234540  len y_train: 234540 \n",
      "len x_dev   : 26061  len y_dev  : 26061 \n",
      "len x_test  : 86868\n"
     ]
    }
   ],
   "source": [
    "print(\"len x_train : %d  len y_train: %d \" %(len(x_train),len(y_train)) )\n",
    "print(\"len x_dev   : %d  len y_dev  : %d \" %(len(x_dev),len(y_dev)) )\n",
    "print(\"len x_test  : %d\" %(len(x_test)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Algorithms from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(10),\n",
    "    DecisionTreeClassifier(max_depth=8),\n",
    "    RandomForestClassifier(max_depth=8, n_estimators=1500, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "\tscore_train:  0.7590943975441289\n",
      "\tscore_dev:  0.7123671386362764\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "\tscore_train:  0.6749765498422444\n",
      "\tscore_dev:  0.6734584244656767\n",
      "\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\tscore_train:  0.569143856058668\n",
      "\tscore_dev:  0.5676297916426845\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net\n",
      "\tscore_train:  0.5732241835081436\n",
      "\tscore_dev:  0.573539004642953\n",
      "\n",
      "\n",
      "\n",
      "AdaBoost\n",
      "\tscore_train:  0.6452801227935533\n",
      "\tscore_dev:  0.6440658455162888\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "\tscore_train:  0.43056621471817175\n",
      "\tscore_dev:  0.43022140362994515\n",
      "\n",
      "\n",
      "\n",
      "QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tscore_train:  0.37562036326426196\n",
      "\tscore_dev:  0.37515828249107863\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results_sklearn = pd.DataFrame(columns=[\"algorithm\",\"acc_train\",\"acc_dev\",\"precision_1\",\"recall_1\",\"f1-score_1\",\"precision_2\",\"recall_2\",\"f1-score_2\",\"precision_3\",\"recall_3\",\"f1-score_3\"])\n",
    "for name, clf in zip(names, classifiers):\n",
    "        print(name)\n",
    "        clf.fit(x_train, y_train)\n",
    "        score_train = clf.score(x_train, y_train)\n",
    "        score_dev = clf.score(x_dev, y_dev)\n",
    "        print(\"\\tscore_train: \",score_train)\n",
    "        print(\"\\tscore_dev: \",score_dev)\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "        pred_y_pred = clf.predict(x_dev)\n",
    "        \n",
    "        dict_report = classification_report(y_dev, pred_y_pred,output_dict=True)\n",
    "        precision_1 = dict_report[\"1\"][\"precision\"]\n",
    "        precision_2 = dict_report[\"2\"][\"precision\"]\n",
    "        precision_3 = dict_report[\"3\"][\"precision\"]\n",
    "        \n",
    "        recall_1 = dict_report[\"1\"][\"recall\"]\n",
    "        recall_2 = dict_report[\"2\"][\"recall\"]\n",
    "        recall_3 = dict_report[\"3\"][\"recall\"]\n",
    "        \n",
    "        score_1 = dict_report[\"1\"][\"f1-score\"]\n",
    "        score_2 = dict_report[\"2\"][\"f1-score\"]\n",
    "        score_3 = dict_report[\"3\"][\"f1-score\"]\n",
    "        \n",
    "        df_results_sklearn = df_results_sklearn.append({\"algorithm\": name,\"acc_train\":score_train,\"acc_dev\":score_dev,\"precision_1\" : precision_1, \"recall_1\" : recall_1, \"f1-score_1\" : score_1,\"precision_2\" : precision_2, \"recall_2\" : recall_2, \"f1-score_2\" : score_2,\"precision_3\" : precision_3, \"recall_3\" : recall_3, \"f1-score_3\" : score_3} , ignore_index=True)\n",
    "        df_results_sklearn.to_csv(\"results/df_results_sklearn_alg.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 100\n"
     ]
    }
   ],
   "source": [
    "# My gridsearch (greedy)\n",
    "\n",
    "df_results_XGBoost = pd.DataFrame(columns=[\"acc_train\",\"acc_dev\",\"max_depth\",\"n_estimator\",\"precision_1\",\"recall_1\",\"f1-score_1\",\"precision_2\",\"recall_2\",\"f1-score_2\",\"precision_3\",\"recall_3\",\"f1-score_3\"])\n",
    "\n",
    "max_depth = 6\n",
    "n_estimators =  range(100,2100,100)\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    print(\"n_estimators:\",n_estimator)\n",
    "\n",
    "    model = xgb.XGBClassifier(n_estimators=n_estimator,max_depth=max_depth)\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_dev_pred = model.predict(x_dev)\n",
    "    \n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_dev = accuracy_score(y_dev, y_dev_pred)\n",
    "    \n",
    "    pred_y_pred = clf.predict(x_dev)\n",
    "        \n",
    "    dict_report = classification_report(y_dev, pred_y_pred,output_dict=True)\n",
    "    precision_1 = dict_report[\"1\"][\"precision\"]\n",
    "    precision_2 = dict_report[\"2\"][\"precision\"]\n",
    "    precision_3 = dict_report[\"3\"][\"precision\"]\n",
    "\n",
    "    recall_1 = dict_report[\"1\"][\"recall\"]\n",
    "    recall_2 = dict_report[\"2\"][\"recall\"]\n",
    "    recall_3 = dict_report[\"3\"][\"recall\"]\n",
    "\n",
    "    score_1 = dict_report[\"1\"][\"f1-score\"]\n",
    "    score_2 = dict_report[\"2\"][\"f1-score\"]\n",
    "    score_3 = dict_report[\"3\"][\"f1-score\"]\n",
    "    \n",
    "    df_results_XGBoost = df_results_XGBoost.append({\"acc_train\":accuracy_train,\"acc_dev\":accuracy_dev,\"max_depth\":max_depth, \"n_estimator\":n_estimator, \"precision_1\" : precision_1, \"recall_1\" : recall_1, \"f1-score_1\" : score_1,\"precision_2\" : precision_2, \"recall_2\" : recall_2, \"f1-score_2\" : score_2,\"precision_3\" : precision_3, \"recall_3\" : recall_3, \"f1-score_3\" : score_3} , ignore_index=True)\n",
    "    df_results_XGBoost.to_csv(\"results/df_results_XGBoost.csv\")\n",
    "    del model\n",
    "    print(\"\\taccuracy_train\",accuracy_train)\n",
    "    print(\"\\taccuracy_dev\",accuracy_dev)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
